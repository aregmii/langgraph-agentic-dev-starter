# Code Agent Project

LangGraph-based code generation agent with SSE streaming.

## Project Structure

```
agent-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”œâ”€â”€ logging_utils.py     # Request-traced logging
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes.py        # POST /tasks (SSE stream)
â”‚   â”‚   â””â”€â”€ workflow_events.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ code_agent.py    # CodeAgent class
â”‚   â”‚   â””â”€â”€ task_execution.py # TaskExecution with progress
â”‚   â””â”€â”€ llm/
â”‚       â”œâ”€â”€ grok_client.py   # Real Grok API
â”‚       â””â”€â”€ mock_client.py   # Mock for testing
â””â”€â”€ static/
    â””â”€â”€ test-sse.html        # Browser test UI
```

## Quick Start

```bash
cd ~/Workspace/langgraph-agentic-dev-starter/agent-service
source ../.venv/bin/activate

# Mock mode (free, fast)
USE_MOCK_LLM=true uvicorn app.main:app --reload

# Real mode (uses API credits)
uvicorn app.main:app --reload

# Open test UI
open http://localhost:8000/static/test-sse.html
```

## Server Logs

Logs are prefixed with request ID for tracing:
```
[req-a1b2c3d4] ðŸ†• NEW REQUEST
[req-a1b2c3d4] â†’ [CodeAgent] Classifying task type using LLM...
[req-a1b2c3d4] âœ“ Done (202ms) â†’ Task type: code_generation
```

Filter by request: `grep "req-a1b2c3d4" /tmp/server.log`
